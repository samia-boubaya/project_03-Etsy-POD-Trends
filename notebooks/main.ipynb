{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0661caf3",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">Project 03: Etsy POD Trends Web scrapping & Analysis</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204b866",
   "metadata": {},
   "source": [
    "### BUSINESS IDEA: ```POD BUSINESS``` \n",
    "\n",
    "### PROBLEM:\n",
    "\n",
    "### SOLUTION:\n",
    "\n",
    "BUSINESS IDEA -> PROBLEM -> RESEARCH + CHART/PLOTS -> INSIGHTS -> INTERPRETATIONS -> IMPLICATIONS -> BUSINESS IMPACT |-> LIMITATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d8ffe",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">CODE</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cbcc66",
   "metadata": {},
   "source": [
    "Etsy is a dynamic website, so scraping it requires careful handling.\n",
    "\n",
    "Since Etsy uses JavaScript to load some content,\n",
    "\n",
    "requests +  ``BeautifulSoup`` might work for static parts (like search results), \n",
    "\n",
    "but for dynamic content, ``Selenium`` is more reliable. \n",
    "\n",
    "I will be using ``requests`` + ``BeautifulSoup`` for **product listings** (title, price, link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65738d",
   "metadata": {},
   "source": [
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6873625",
   "metadata": {},
   "source": [
    "#### **INSTALL LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5545aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requests & beautifulsoup\n",
    "!pip install requests beautifulsoup4 fake-useragent stem pandas\n",
    "\n",
    "# install selenium\n",
    "!pip install selenium pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3073d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching TOR...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'tor' isn't available on your system. Maybe it's not in your PATH?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOR identity change failed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_TOR:\n\u001b[1;32m---> 52\u001b[0m     tor_process \u001b[38;5;241m=\u001b[39m start_tor()\n\u001b[0;32m     53\u001b[0m     proxies \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocks5://127.0.0.1:9050\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocks5://127.0.0.1:9050\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m     }\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[10], line 33\u001b[0m, in \u001b[0;36mstart_tor\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstart_tor\u001b[39m():\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching TOR...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stem\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mlaunch_tor_with_config(\n\u001b[0;32m     34\u001b[0m         config\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSocksPort\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9050\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mControlPort\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9051\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCookieAuthentication\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m         },\n\u001b[0;32m     39\u001b[0m         take_ownership\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\stem\\process.py:285\u001b[0m, in \u001b[0;36mlaunch_tor_with_config\u001b[1;34m(config, tor_cmd, completion_percent, init_msg_handler, timeout, take_ownership, close_output)\u001b[0m\n\u001b[0;32m    282\u001b[0m       config_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (key, value)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_stdin:\n\u001b[1;32m--> 285\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m launch_tor(tor_cmd, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-f\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, completion_percent, init_msg_handler, timeout, take_ownership, close_output, stdin \u001b[38;5;241m=\u001b[39m config_str)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m   torrc_descriptor, torrc_path \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mmkstemp(prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorrc-\u001b[39m\u001b[38;5;124m'\u001b[39m, text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\stem\\process.py:103\u001b[0m, in \u001b[0;36mlaunch_tor\u001b[1;34m(tor_cmd, args, torrc_path, completion_percent, init_msg_handler, timeout, take_ownership, close_output, stdin)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m tor_cmd)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stem\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39msystem\u001b[38;5;241m.\u001b[39mis_available(tor_cmd):\n\u001b[1;32m--> 103\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt available on your system. Maybe it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms not in your PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m tor_cmd)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# double check that we have a torrc to work with\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torrc_path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, NO_TORRC) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(torrc_path):\n",
      "\u001b[1;31mOSError\u001b[0m: 'tor' isn't available on your system. Maybe it's not in your PATH?"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import stem.process\n",
    "from stem import Signal\n",
    "from stem.control import Controller\n",
    "\n",
    "# 1. CONFIGURATION --------------------------------------------------------------------------------------\n",
    "\n",
    "SEARCH_QUERY = \"handmade bag\"\n",
    "BASE_URL = f\"https://www.etsy.com/search?q={SEARCH_QUERY.replace(' ', '+')}\"\n",
    "\n",
    "USE_TOR = True              # Turn TOR IP rotation on/off\n",
    "MAX_RETRIES = 5\n",
    "MIN_DELAY = 4               # Minimum delay between requests\n",
    "MAX_DELAY = 12              # Maximum delay\n",
    "PROXY_LIST = [\n",
    "    # \"http://user:pass@ip:port\",\n",
    "    # \"http://ip:port\",\n",
    "]\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "\n",
    "# 2. TOR SETUP (optional but recommended) --------------------------------------------------------------\n",
    "def start_tor():\n",
    "    print(\"Launching TOR...\")\n",
    "    return stem.process.launch_tor_with_config(\n",
    "        config={\n",
    "            \"SocksPort\": \"9050\",\n",
    "            \"ControlPort\": \"9051\",\n",
    "            \"CookieAuthentication\": \"1\",\n",
    "        },\n",
    "        take_ownership=True,\n",
    "    )\n",
    "\n",
    "def new_tor_identity():\n",
    "    try:\n",
    "        with Controller.from_port(port=9051) as controller:\n",
    "            controller.authenticate()\n",
    "            controller.signal(Signal.NEWNYM)\n",
    "        print(\"üîÑ TOR: New identity requested.\")\n",
    "    except Exception as e:\n",
    "        print(\"TOR identity change failed:\", e)\n",
    "\n",
    "if USE_TOR:\n",
    "    tor_process = start_tor()\n",
    "    proxies = {\n",
    "        \"http\": \"socks5://127.0.0.1:9050\",\n",
    "        \"https\": \"socks5://127.0.0.1:9050\",\n",
    "    }\n",
    "else:\n",
    "    proxies = None  # Will use rotating HTTP proxies later\n",
    "\n",
    "# 3. RANDOMIZED HEADERS ---------------------------------------------------------------------------\n",
    "def random_headers():\n",
    "    return {\n",
    "        \"User-Agent\": ua.random,\n",
    "        \"Accept-Language\": random.choice([\n",
    "            \"en-US,en;q=0.8\",\n",
    "            \"en-GB,en;q=0.7\",\n",
    "            \"fr-FR,fr;q=0.9\",\n",
    "            \"de-DE,de;q=0.8\"\n",
    "        ]),\n",
    "        \"Referer\": random.choice([\n",
    "            \"https://www.google.com\",\n",
    "            \"https://www.bing.com\",\n",
    "            \"https://duckduckgo.com\",\n",
    "        ]),\n",
    "        \"DNT\": str(random.choice([0, 1])),\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Mode\": random.choice([\"navigate\", \"same-origin\"]),\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "    }\n",
    "\n",
    "# 4. SAFE REQUEST FUNCTION ------------------------------------------------------------------------------\n",
    "\n",
    "def safe_get(url):\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        \n",
    "        # Random proxy from list (if not using TOR)\n",
    "        proxy = {\"http\": random.choice(PROXY_LIST),\n",
    "                 \"https\": random.choice(PROXY_LIST)} if (PROXY_LIST and not USE_TOR) else proxies\n",
    "\n",
    "        try:\n",
    "            headers = random_headers()\n",
    "            print(f\"[Attempt {attempt}] Fetching: {url}\")\n",
    "            print(\"Headers:\", headers[\"User-Agent\"])\n",
    "\n",
    "            response = requests.get(\n",
    "                url,\n",
    "                headers=headers,\n",
    "                proxies=proxy,\n",
    "                timeout=15\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                print(\"‚úî Success\")\n",
    "                return response\n",
    "            \n",
    "            print(f\"‚ö† Status {response.status_code}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Error:\", e)\n",
    "\n",
    "        # Request new TOR identity after failures\n",
    "        if USE_TOR:\n",
    "            new_tor_identity()\n",
    "\n",
    "        # Backoff delay\n",
    "        delay = random.uniform(MIN_DELAY * attempt, MAX_DELAY * attempt)\n",
    "        print(f\"‚è≥ Waiting {delay:.2f}s before retry...\\n\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    raise Exception(\"Failed after max retries.\")\n",
    "\n",
    "\n",
    "# 5. SCRAPING -------------------------------------------------------------------------------------\n",
    "\n",
    "response = safe_get(BASE_URL)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "titles, prices, links = [], [], []\n",
    "\n",
    "products = soup.find_all(\"li\", class_=\"wt-list-unstyled\")\n",
    "\n",
    "for p in products:\n",
    "    t = p.find(\"h3\")\n",
    "    c = p.find(\"span\", class_=\"currency-value\")\n",
    "    a = p.find(\"a\", href=True)\n",
    "\n",
    "    if t and c and a:\n",
    "        titles.append(t.get_text(strip=True))\n",
    "        prices.append(c.get_text(strip=True))\n",
    "        links.append(a[\"href\"])\n",
    "\n",
    "\n",
    "# 6. SAVE CSV & DISPLAY -------------------------------------------------------------------\n",
    "\n",
    "df = pd.DataFrame({\"Title\": titles, \"Price\": prices, \"Link\": links})\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"etsy_scrape_protected.csv\", index=False)\n",
    "print(\"\\nSaved as etsy_scrape_protected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ecb2c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sboub\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\sboub\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sboub\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "SOCKSHTTPSConnectionPool(host='www.etsy.com', port=443): Max retries exceeded with url: /search?q=t-shirt (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x000002D8D81CF890>: Failed to establish a new connection: [WinError 10061] Aucune connexion n‚Äôa pu √™tre √©tablie car l‚Äôordinateur cible l‚Äôa express√©ment refus√©e'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\socks.py:787\u001b[0m, in \u001b[0;36msocksocket.connect\u001b[1;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Initial connection to proxy server.\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m     \u001b[38;5;28msuper\u001b[39m(socksocket, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconnect(proxy_addr)\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;66;03m# Error while connecting to proxy\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Aucune connexion n‚Äôa pu √™tre √©tablie car l‚Äôordinateur cible l‚Äôa express√©ment refus√©e",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProxyConnectionError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\contrib\\socks.py:110\u001b[0m, in \u001b[0;36mSOCKSConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     conn \u001b[38;5;241m=\u001b[39m socks\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    111\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    112\u001b[0m         proxy_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socks_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocks_version\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    113\u001b[0m         proxy_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socks_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_host\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    114\u001b[0m         proxy_port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socks_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    115\u001b[0m         proxy_username\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socks_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    116\u001b[0m         proxy_password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socks_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    117\u001b[0m         proxy_rdns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socks_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrdns\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    118\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw,\n\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\socks.py:209\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err:\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgai returned empty list.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\socks.py:199\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[0;32m    197\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 199\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect((remote_host, remote_port))\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\socks.py:47\u001b[0m, in \u001b[0;36mset_self_blocking.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetblocking(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\socks.py:800\u001b[0m, in \u001b[0;36msocksocket.connect\u001b[1;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[0;32m    799\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m due to: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, msg, error)\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProxyConnectionError(msg, error)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mProxyConnectionError\u001b[0m: Error connecting to SOCKS5 proxy 127.0.0.1:9050: [WinError 10061] Aucune connexion n‚Äôa pu √™tre √©tablie car l‚Äôordinateur cible l‚Äôa express√©ment refus√©e",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:704\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    703\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    705\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\contrib\\socks.py:141\u001b[0m, in \u001b[0;36mSOCKSConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;66;03m# Adding `from e` messes with coverage somehow, so it's omitted.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;66;03m# See #2386.\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m         )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x000002D8D81CF890>: Failed to establish a new connection: [WinError 10061] Aucune connexion n‚Äôa pu √™tre √©tablie car l‚Äôordinateur cible l‚Äôa express√©ment refus√©e",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    842\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    843\u001b[0m )\n\u001b[0;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: SOCKSHTTPSConnectionPool(host='www.etsy.com', port=443): Max retries exceeded with url: /search?q=t-shirt (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x000002D8D81CF890>: Failed to establish a new connection: [WinError 10061] Aucune connexion n‚Äôa pu √™tre √©tablie car l‚Äôordinateur cible l‚Äôa express√©ment refus√©e'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 42\u001b[0m\n\u001b[0;32m     37\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mrandom_headers(), proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     44\u001b[0m titles \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m prices \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: SOCKSHTTPSConnectionPool(host='www.etsy.com', port=443): Max retries exceeded with url: /search?q=t-shirt (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x000002D8D81CF890>: Failed to establish a new connection: [WinError 10061] Aucune connexion n‚Äôa pu √™tre √©tablie car l‚Äôordinateur cible l‚Äôa express√©ment refus√©e'))"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install requests beautifulsoup4 fake-useragent pandas\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "# -------------------------\n",
    "# Random headers function\n",
    "# -------------------------\n",
    "ua = UserAgent()\n",
    "def random_headers():\n",
    "    return {\n",
    "        \"User-Agent\": ua.random,\n",
    "        \"Accept-Language\": random.choice([\"en-US,en;q=0.8\",\"fr-FR,fr;q=0.9\"]),\n",
    "        \"Referer\": \"https://www.google.com\"\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Tor proxy (must run Tor manually first)\n",
    "# -------------------------\n",
    "proxies = {\n",
    "    \"http\": \"socks5://127.0.0.1:9050\",\n",
    "    \"https\": \"socks5://127.0.0.1:9050\",\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Etsy search URL\n",
    "# -------------------------\n",
    "search_query = \"t-shirt\"\n",
    "url = f\"https://www.etsy.com/search?q={search_query.replace(' ', '+')}\"\n",
    "\n",
    "# Random delay\n",
    "time.sleep(random.uniform(3, 8))\n",
    "\n",
    "# -------------------------\n",
    "# Send request\n",
    "# -------------------------\n",
    "response = requests.get(url, headers=random_headers(), proxies=proxies, timeout=15)\n",
    "\n",
    "titles = []\n",
    "prices = []\n",
    "ratings = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Each product is in a <li> tag with specific class\n",
    "    products = soup.find_all(\"li\", class_=\"wt-list-unstyled\")  # adjust as needed\n",
    "\n",
    "    for product in products:\n",
    "        # Title\n",
    "        title_tag = product.find(\"h3\")\n",
    "        title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "        # Price\n",
    "        price_tag = product.find(\"span\", class_=\"currency-value\")\n",
    "        price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "        # Rating (optional)\n",
    "        rating_tag = product.find(\"span\", class_=\"screen-reader-only\")\n",
    "        rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "        if title:\n",
    "            titles.append(title)\n",
    "            prices.append(price)\n",
    "            ratings.append(rating)\n",
    "\n",
    "    # -------------------------\n",
    "    # Create DataFrame\n",
    "    # -------------------------\n",
    "    df = pd.DataFrame({\n",
    "        \"Title\": titles,\n",
    "        \"Price\": prices,\n",
    "        \"Rating\": ratings\n",
    "    })\n",
    "\n",
    "    print(df.head())\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch page. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07d1af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sboub\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\sboub\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sboub\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sboub\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Scraping page 1...\n",
      "Failed to fetch page 1. Status code: 403\n",
      "Scraping page 2...\n",
      "Failed to fetch page 2. Status code: 403\n",
      "Scraping page 3...\n",
      "Failed to fetch page 3. Status code: 403\n",
      "Empty DataFrame\n",
      "Columns: [Title, Price, Rating]\n",
      "Index: []\n",
      "Saved results to etsy_tshirt_products.csv\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "!pip install requests beautifulsoup4 fake-useragent pandas\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "# -------------------------\n",
    "# Random headers function\n",
    "# -------------------------\n",
    "ua = UserAgent()\n",
    "def random_headers():\n",
    "    return {\n",
    "        \"User-Agent\": ua.random,\n",
    "        \"Accept-Language\": random.choice([\"en-US,en;q=0.8\",\"fr-FR,fr;q=0.9\"]),\n",
    "        \"Referer\": \"https://www.google.com\"\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Tor proxy (Tor must be running manually)\n",
    "# -------------------------\n",
    "proxies = {\n",
    "    \"http\": \"socks5://127.0.0.1:9050\",  # check your Tor log if different\n",
    "    \"https\": \"socks5://127.0.0.1:9050\",\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Search query\n",
    "# -------------------------\n",
    "search_query = \"t-shirt\"\n",
    "base_url = \"https://www.etsy.com/search\"\n",
    "\n",
    "# Data storage\n",
    "titles = []\n",
    "prices = []\n",
    "ratings = []\n",
    "\n",
    "# -------------------------\n",
    "# Scrape multiple pages\n",
    "# -------------------------\n",
    "for page in range(1, 4):  # first 3 pages, change as needed\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    params = {\n",
    "        \"q\": search_query,\n",
    "        \"ref\": \"search_bar\",\n",
    "        \"page\": page\n",
    "    }\n",
    "\n",
    "    # Random delay to reduce blocking\n",
    "    time.sleep(random.uniform(3, 7))\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, headers=random_headers(), proxies=proxies, params=params, timeout=15)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {page}. Status code: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Each product\n",
    "        products = soup.find_all(\"li\", class_=\"wt-list-unstyled\")  # Etsy product container\n",
    "\n",
    "        for product in products:\n",
    "            # Title\n",
    "            title_tag = product.find(\"h3\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "            # Price\n",
    "            price_tag = product.find(\"span\", class_=\"currency-value\")\n",
    "            price = price_tag.get_text(strip=True) if price_tag else None\n",
    "\n",
    "            # Rating (optional)\n",
    "            rating_tag = product.find(\"span\", class_=\"screen-reader-only\")\n",
    "            rating = rating_tag.get_text(strip=True) if rating_tag else None\n",
    "\n",
    "            if title:\n",
    "                titles.append(title)\n",
    "                prices.append(price)\n",
    "                ratings.append(rating)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "        continue\n",
    "\n",
    "# -------------------------\n",
    "# Create DataFrame\n",
    "# -------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Price\": prices,\n",
    "    \"Rating\": ratings\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "# Save to CSV\n",
    "df.to_csv(\"etsy_tshirt_products.csv\", index=False)\n",
    "print(\"Saved results to etsy_tshirt_products.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3273f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ua = UserAgent()\n",
    "\n",
    "def random_headers():\n",
    "    return {\n",
    "        \"User-Agent\": ua.random,\n",
    "        \"Accept-Language\": random.choice([\"en-US,en;q=0.8\", \"fr-FR,fr;q=0.9\"]),\n",
    "        \"Referer\": \"https://www.google.com\"\n",
    "    }\n",
    "\n",
    "proxies = {\n",
    "    \"http\": \"socks5://127.0.0.1:9050\",\n",
    "    \"https\": \"socks5://127.0.0.1:9050\",\n",
    "}\n",
    "\n",
    "url = \"https://www.etsy.com/search?q=handmade+bag\"\n",
    "\n",
    "# Random delay\n",
    "import time\n",
    "time.sleep(random.uniform(3, 8))\n",
    "\n",
    "response = requests.get(url, headers=random_headers(), proxies=proxies, timeout=15)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "print(soup.title.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c84d9e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDriverException",
     "evalue": "Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:65\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(path)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe path is not a valid file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m path\n",
      "\u001b[1;31mValueError\u001b[0m: The path is not a valid file: C:\\Path\\To\\chromedriver.exe",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNoSuchDriverException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Path to ChromeDriver\u001b[39;00m\n\u001b[0;32m     20\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchromedriver.exe\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# change to your path\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mservice, options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Etsy search\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m     26\u001b[0m search_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-shirt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:47\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     44\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     45\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     48\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     49\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m     51\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[0;32m     52\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m     53\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:55\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     52\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m ChromiumOptions()\n\u001b[0;32m     54\u001b[0m finder \u001b[38;5;241m=\u001b[39m DriverFinder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice, options)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m finder\u001b[38;5;241m.\u001b[39mget_browser_path():\n\u001b[0;32m     56\u001b[0m     options\u001b[38;5;241m.\u001b[39mbinary_location \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mget_browser_path()\n\u001b[0;32m     57\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:48\u001b[0m, in \u001b[0;36mDriverFinder.get_browser_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_browser_path\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_binary_paths()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowser_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sboub\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:79\u001b[0m, in \u001b[0;36mDriverFinder._binary_paths\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     78\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to obtain driver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrowser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paths\n",
      "\u001b[1;31mNoSuchDriverException\u001b[0m: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# -------------------------\n",
    "# Tor proxy settings\n",
    "# -------------------------\n",
    "tor_socks_port = 9050  # check your Tor log\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # run without opening browser\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--proxy-server=socks5://127.0.0.1:{}\".format(tor_socks_port))\n",
    "\n",
    "# Path to ChromeDriver\n",
    "service = Service(r\"C:\\Path\\To\\chromedriver.exe\")  # change to your path\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# -------------------------\n",
    "# Etsy search\n",
    "# -------------------------\n",
    "search_query = \"t-shirt\"\n",
    "url = f\"https://www.etsy.com/search?q={search_query.replace(' ', '+')}\"\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(random.uniform(3,6))  # random delay\n",
    "\n",
    "# -------------------------\n",
    "# Scrape product info\n",
    "# -------------------------\n",
    "titles = []\n",
    "prices = []\n",
    "ratings = []\n",
    "\n",
    "# Etsy uses divs with data-search-result attribute\n",
    "products = driver.find_elements(By.CSS_SELECTOR, \"li[data-search-result]\")\n",
    "\n",
    "for product in products:\n",
    "    try:\n",
    "        title = product.find_element(By.TAG_NAME, \"h3\").text\n",
    "    except:\n",
    "        title = None\n",
    "    try:\n",
    "        price = product.find_element(By.CSS_SELECTOR, \"span.currency-value\").text\n",
    "    except:\n",
    "        price = None\n",
    "    try:\n",
    "        rating = product.find_element(By.CSS_SELECTOR, \"span.screen-reader-only\").text\n",
    "    except:\n",
    "        rating = None\n",
    "\n",
    "    if title:\n",
    "        titles.append(title)\n",
    "        prices.append(price)\n",
    "        ratings.append(rating)\n",
    "\n",
    "# -------------------------\n",
    "# Save to DataFrame\n",
    "# -------------------------\n",
    "df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Price\": prices,\n",
    "    \"Rating\": ratings\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Optional: save to CSV\n",
    "df.to_csv(\"etsy_tshirt_selenium.csv\", index=False)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a53c04",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">INSIGHTS</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08997c",
   "metadata": {},
   "source": [
    "### INSIGHT 01:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01c223",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">RESEARCH</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc370b1",
   "metadata": {},
   "source": [
    "### üåê **Which Are the Best-Selling POD Products on Etsy?**\n",
    "\n",
    "I‚Äôm researching print-on-demand products to sell on Etsy that only require **digital artwork and marketing**, while the POD provider handles **printing, packaging, and shipping**.\n",
    "\n",
    "\n",
    "### ‚≠ê Using Google Trends for POD Product Research\n",
    "üí° **Goal:** Identify which POD product category has been searched the most on Google over the past 5 years (2020‚Äì2025).\n",
    "\n",
    "Below is the list of product categories I‚Äôm comparing:\n",
    "\n",
    "1. ```Custom Apparel```\n",
    "    - T-shirts  \n",
    "    - Hoodies  \n",
    "    - Sweatshirts  \n",
    "    - Tank tops \n",
    "\n",
    "2. ```Mug```\n",
    "    - Ceramic mugs  \n",
    "    - Color-changing mugs  \n",
    "    - Espresso mugs  \n",
    "    - Travel mugs \n",
    "\n",
    "3. ```Tote Bag```\n",
    "    - Cotton totes  \n",
    "    - All-over print totes  \n",
    "\n",
    "4. ```Phone Case```\n",
    "    - iPhone / Samsung cases  \n",
    "    - Tough / Slim cases  \n",
    "\n",
    "5. ```Stickers```\n",
    "    - Die-cut stickers  \n",
    "    - Kiss-cut stickers  \n",
    "    - Sticker sheets \n",
    "\n",
    "6. ```Hats```\n",
    "    - Baseball caps  \n",
    "    - Trucker hats  \n",
    "    - Beanies  \n",
    "\n",
    "7. ```Pillows / Cushions```\n",
    "    - Pillow covers  \n",
    "    - Stuffed pillows  \n",
    "    - All-over print pillow designs  \n",
    "\n",
    "8. ```Blanket```\n",
    "    - Fleece blankets  \n",
    "    - Sherpa blankets  \n",
    "    - Woven blankets  \n",
    "\n",
    "9. ```Wall Art```\n",
    "    - Posters  \n",
    "    - Canvas prints  \n",
    "    - Framed posters  \n",
    "    - Metal prints  \n",
    "\n",
    "10. ```Doormat```\n",
    "    - Printed coir doormats  \n",
    "    - Rubber-backed doormats \n",
    "\n",
    "11. ```Drinkware```\n",
    "    - Stainless steel tumblers  \n",
    "    - Water bottles  \n",
    "    - Wine tumblers \n",
    "\n",
    "12. ```Calendar```\n",
    "    - Custom printed wall calendars  \n",
    "\n",
    "13. ```Yoga Mat```\n",
    "    - Printed yoga mats \n",
    "\n",
    "14. ```Bedding```\n",
    "    - Duvet covers  \n",
    "    - Pillowcases  \n",
    "    - All-over print bed sets\n",
    "\n",
    "15. ```Pet Accessories```\n",
    "    - Pet bandanas  \n",
    "    - Pet beds  \n",
    "    - Pet bowls  \n",
    "    - Pet blankets  \n",
    "\n",
    "16. ```Ornaments```\n",
    "    - Ceramic ornaments\n",
    "    - Wood ornaments\n",
    "    - Metal ornaments \n",
    "\n",
    "------\n",
    "### The POD product I chose to research is : custom Calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59c7d6",
   "metadata": {},
   "source": [
    "aria-label=\"4.9 star rating with 398 reviews\"\n",
    "\n",
    "etsy store selling print on demand products\n",
    "\n",
    "data needed\n",
    "- product title keywords to use to optimize sales / using title\n",
    "- product description keywords / \n",
    "- insight the niches based on most selling keywords\n",
    "- period when to sell / using reviews\n",
    "- price / most selling price tag and range\n",
    "- targeted audience ?\n",
    "- how to market it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b6165",
   "metadata": {},
   "source": [
    "Chosen website for Data Scraping : Etsy\n",
    "\n",
    "data to extract : \n",
    "\n",
    "- product_title, for the keywords used in it to analyse the niche of this POD product\n",
    "\n",
    "- product_price, for figuring the best price to sell it at\n",
    "\n",
    "- product_listing_date, the date this product got created and added on etsy \n",
    "\n",
    "- product_rating, to know which niche in this POD product is selling the most \n",
    "- product_niche_rating\n",
    "\n",
    "- product_reviews_date, to compare nbr_review vs nbr_orders \n",
    "and to have a plot showing the rating of this product over time\n",
    "when did those sales happen the most and if it was recent or not\n",
    "two products can be sold with the same amount of orders but\n",
    "at different lengths of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c47e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_category : t-shirt, mug, calendar,...\n",
    "# product_niche : comedy, drama, horror, halloween, cartoon, anime, ... \n",
    "# product_price :  in euros\n",
    "# product_listing_date: 00/00/0000 date created and added to etsy on product page\n",
    "# product_rating: 0.0/5 current rating of the product to compare\n",
    "# product_reviews_ratings: DataFrame with reviews ratings of each product from product page\n",
    "# product_reviews_dates: DataFrame with reviews dates of each product from product page\n",
    "# product_reviews_date: DataFrame with reviews descriptions of each product from product page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf6a73",
   "metadata": {},
   "source": [
    "==================================================================================================================================\n",
    "# <div align=\"center\">DATA VISUALIZATION (CHARTS/PLOTS)</div>\n",
    "=================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001cf4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa276733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8c1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d36191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee723ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
